{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"cartographic modeling","text":"<p>A collection of concepts, methods, problems, and workflows that apply cartographic modeling to landscape analysis and planning with Google Earth Engine and Whitebox Tools Open Core.      </p> <p>Jeff Howarth Geography Department Middlebury College</p>"},{"location":"challenges/clearings/","title":"clearings","text":""},{"location":"challenges/clearings/#introduction","title":"introduction","text":"<p>This problem is based on work that I did for the Town of Cornwall\u2019s Conservation Commission in Vermont as part of an effort to create an atlas of wildlife habitat connectivity.  </p> <p>I wanted to make a map that showed locations that were in some stage of recovery from human disturbance; locations where successional processes were playing a role in the structure and composition of land cover, as opposed to places where human activity was the dominant influence on structure and composition.  </p> <p>I also wanted to avoid both the weeds and the baggage of human vs. nature thinking. So I did not care so much if people cut down trees or sugared or extracted resources from land as long as these activities did not interrupt successional processes from playing a role in the structure and composition of land cover over an extended interval of time.     </p> <p>One approach to this problem is to bring together maps of undisturbed lands, like tree canopy, wetlands, surface waters. In other words, this approach aims to map the positive values of space. Vermont Conservation Design is a good example of this approach. This project mapped habitat blocks by first identifying positive values of space and then subtracting small parts from them (for example, removing zones influenced by roads within blocks). </p> <p>For the Cornwall project, I tried a different approach. I first mapped the negative values of space for forest wildlife habitat and then took the inverse to map the positive space for forest wildlife habitat. I thought this reflected the ecological history of Vermont when white immigrants and their industries cleared the indigenous forest in the process of settling the land. So I mapped things that cleared underlying land cover and then took the inverse of this to map recovering lands.     </p> <p>I found this approach to require a simpler model (with fewer steps) than the alternative approach. </p>"},{"location":"challenges/clearings/#challenge","title":"challenge","text":"<p>Make a binary map of clearings for a test region, where clearings use these inputs:  </p> <p> NAME DATA Agricultural lands data.lc.ag e911 Footprints data.e911.footprints Building Roofprints data.lc.buildings Land cover data.lc.base Roads data.lc.roads Railroads data.lc.rr <p> </p> <p>Clearings should identify locations that meet one or more of these 10 conditions:  </p> <p> CONDITION DESCRIPTION 1 Buildings, roads, other pavement, and railroad land cover classes are all clearings. 2 Farm/Vineyard clear all other land cover classes. 3 Quarry/Mine clear all other land covers. 4 Stadium/Arena clear all other land cover. 5 All Alpine glades or trails (both Expert and Easiest) clear all other land cover. 6 Airports clear all other land cover. 7 Buildings have a zone of influence that clears all other land cover within 100 feet. 8 All railroads and roads (except Class 4 roads) clear all other land cover within 50 feet. 9 Ag clears all other land cover except tree canopy and lands within 20 ft of trees. 10 Golf courses clear all land cover except tree canopy and lands within 20 ft of trees. <p></p> <p>Although you could run this analysis for the entire state of Vermont, it is good practice to develop and test a model for a smaller region so that you do not have to wait as long for processes to complete while you write and test your code. For a test region, please select Addison from the county collection (data.gov.county). Use the test region to filter all the feature collections used in your solution.  </p> <p>If your model still runs slowly, you can use a smaller test site (for example, one town in Vermont). Ideally, you want your test site to be small but still representative of the larger study region. For example, in our case, an ideal test site would have both farms/vineyards and ski pistes.   </p> <p>Please note that this problem will require you to select features by attribute for some layers. For example, you will need to isolate farms/vineyards from the e911 footprint layer. To do this, you may find it helpful to look at the \u201cEntity and Attribute Information\u201d in the layer\u2019s metadata. You can find links to metadata in the data repo for e911 footprints and roads. </p>"},{"location":"challenges/clearings/#starter","title":"starter","text":"<pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  CHALLENGE PROBLEM\n//  Clearings in Middlebury, Vermont. \n\n//  Last modified: insert date\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar data = require('users/jhowarth/public:modules/data.js');       print('DATA', data);\n\nvar t = require('users/jhowarth/public:modules/tasks.js');\n</code></pre>"},{"location":"challenges/clearings/#deliverable","title":"deliverable","text":"<p>Write a script that produces a single binary image that satisfies the ten conditions described above.  </p> <p>Please take care to organize your script into meaningful chunks and comment your work. I recommend that you use the header template shown below to keep signify the chunks of your code that satisfies each condition.</p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  CONDITION #\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n</code></pre> <p>No pressure. Give it your best shot. Let me know if you have questions.  </p> <p>We will go over a solution next week with cards.  </p>"},{"location":"challenges/water-story/","title":"water story","text":""},{"location":"challenges/water-story/#introduction","title":"Introduction","text":"<p>This problem introduces a workflow to map nominal values in vector tables with different colors and with casings and fills (borders and interiors). Unfortunately, this is surprisingly difficult to do in earth engine, which is troublesome because a lot of conservation data gets delivered as feature collections (vector tables). So for practical reasons, I would like you to learn some methods to deal with this problem.  </p> <p>This problem is also motivated by a personal pet peeve: I am bothered by maps that do not distinguish between ditches (built by people in the last 100 years to drain wetlands for agriculture) and streams (built through fluvial processes over millennia). I think cartographers have an ethical responsibility to not participate in the erasure of the past and to instead help people remember the past and recognize how recent history has transformed the landscapes we now inhabit. For me, using the same color for streams and ditches does not feel ethically responsible, at best.  </p>"},{"location":"challenges/water-story/#goal","title":"Goal","text":"<p>Please do the following:  </p> <ol> <li>Make a copy of your shaded relief script (called it wk04_03_water_story_challenge.md).</li> <li>Copy the starter script below and paste it into the new script after the shaded relief part.    </li> <li>Read through the script and play with it to try to understand how the wetlands section works. </li> <li>Try to finish styling the stream, ditch, and pond data by completing the last section where I leave you hanging. </li> <li>Ideally, your script should produce the layers shown in the app below.</li> </ol>"},{"location":"challenges/water-story/#starter-script","title":"Starter script","text":"<pre><code>// -------------------------------------------------------------------------\n//  PART II: WATER STORY CHALLENGE\n// -------------------------------------------------------------------------\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  A. WETLANDS\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n//  Load wetland data and filter by region.  \n\nvar wet_class = ee.FeatureCollection(data.wetlands.vswi_class.fc_address)\n.filterBounds(study_region)\n;\n\n//  Print to see what you are working with.  \n\nprint(\n\"WETLANDS\",\nwet_class.first(),\nwet_class.aggregate_array('CLASS').distinct().sort()\n)\n;\n\n//  Load soils, filter by study region, and filter for hydric soils. \n\nvar hydric = ee.FeatureCollection(data.soils.addison.fc_address)\n.filterBounds(study_region)\n.filter(ee.Filter.eq('HYDRIC', 'Y'))\n;\n\n//  Print so you can see what ya got.  \n\nprint(\n'HYDRIC',\nhydric.first(),\nhydric.aggregate_array('HYDRIC').distinct().sort()\n)\n;\n\n// Define a style dictionary for nominal classes. \n\nvar wet_styles = ee.Dictionary({\n\"class1\": {color: '#7F4D84CC', fillColor: '#D7BFD9CC', width: 1},\n\"class2\": {color: '#5C4D85CC', fillColor: '#C6BFD9CC', width: 1},\n\"hydric\": {color: '#4D857780', fillColor: '#BFD9D380', width: 1}\n\n});\n\n//  Make a distinct feature collection for each class \n//  and tag each feature in the layer with a name that matches a key in the dictionary. \n\nvar class1 = t.tag2style(wet_class, 'CLASS', 1, 'class1');\nvar class2 = t.tag2style(wet_class, 'CLASS', 2, 'class2');\nvar hydric = t.tag2style(hydric, 'HYDRIC', 'Y', 'hydric');\n\n//  Merge the three tagged collections into a single feature collection.  \n\nvar wetlands = hydric\n.merge(class2)\n.merge(class1)\n;\n\n//  Print this out so that you can see what the last step did. \n\nprint(\n\"WETLANDS\",\nwetlands )\n;\n\n//  Map the style dictionary to each feature in the collection.\n//  This makes the style parameters a property of each feature in the collection.  \n\nvar wetlands_with_styles = wetlands\n.map(t.fStyle(wet_styles, \"tag\"))\n;\n\n//  Print this out so that you can compare with wetlands and see what the last step did. \n\nprint(\n\"With styles\",\nwetlands_with_styles.first()\n);\n\n// Apply the styles to make an RGB image. \n\nvar wetlands_styles_applied = wetlands_with_styles\n.style({styleProperty: 'style'})\n.updateMask(study_region_binary)\n;\n\n//  Display the RGB image.  Notice how the result now has casings and fills.  \n\nMap.addLayer(wetlands_styles_applied, {}, \"Wetlands - styles applied\" );\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  B. SURFACE WATERS \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+- \n\n// Load stream area data and filter by region. \n\nvar stream_area = ee.FeatureCollection(\"projects/sat-io/open-datasets/NHD/NHD_VT/NHDArea\")\n.filterBounds(study_region)\n;\n\nMap.addLayer(stream_area, {color: 'cyan'}, \"Stream area\", false);\n\n// Load stream line data and filte by region. \n\nvar stream_line = ee.FeatureCollection(\"projects/sat-io/open-datasets/NHD/NHD_VT/NHDFlowline\")\n.filterBounds(study_region)\n;\n\nMap.addLayer(stream_line, {color: 'cyan'}, \"Stream line\", false);\n\n//  Load waterbody data and filter by region.  \n\nvar waterbody = ee.FeatureCollection(\"projects/sat-io/open-datasets/NHD/NHD_VT/NHDWaterbody\")\n.filterBounds(study_region)\n;\n\nMap.addLayer(waterbody, {color: 'cyan'}, \"Waterbody\", false);  //  Print to compare and contrast tables.  \n\nprint(\n\"NHD features\",\nstream_area.first(),\nstream_line.first(),\nwaterbody.first()\n)\n;\n\n//  Here is a cheat sheet for the fcodes in our dataset (standard for the national hydrology dataset)\n//  and a strategy to display them on the map. \n\n//  The goal is to distinguish ditches from other water features;\n//  because ditches were created to drain wetland soils.\n\nvar fcodes = {\n39004: [\"Lake/Pond\", 'natural'],\n33600: [\"Canal/Ditch\", 'ditch'],\n46006: [\"Stream/River perennial\", 'natural'],\n55800: [\"Artificial path\", 'ignore']\n};\n\n//  Here is the style dictionary for natural vs ditch channels. \n\nvar nhd_styles = ee.Dictionary({\n\"natural\": {color: '#688A91', fillColor: '#ACDCE6', width: 2},\n\"ditch\": {color: '#CC8866', fillColor: '#E6C7B8', width: 2},\n})\n;\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  TRY TO COMPLETE THE REMAINDER OF THIS SCRIPT \n//  TO DISPLAY THE WATER FEATURES AS SHOWN IN THE APP.\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n</code></pre>"},{"location":"challenges-wb/extract-streams/","title":"extract streams from dem","text":""},{"location":"challenges-wb/extract-streams/#problem","title":"Problem","text":"<p>Please write a python script that uses whitebox tools to extract streams from a DEM. Please use the \u201cdem_clipped_practice.tif\u201d from the vermont lidar tutorial.  </p>"},{"location":"challenges-wb/extract-streams/#workflow","title":"Workflow","text":"<p> <pre><code>graph TD\n\n  00((DEM)) ;\n  01[BreachDepressionsLeastCost] ;\n  02[Rho8Pointer] ;\n  03[Rho8FlowAccumulation] ;\n  04[ExtractStreams] ;\n  05[StrahlerStreamOrder] ;\n  06[RasterStreamsToVector] ;\n  07((&amp;#128526)) ;\n\n  00 --&gt; 01\n  01 --&gt; 02 \n  02 --&gt; 03  \n  03 --&gt; 04\n  04 --&gt; 05\n  02 --&gt; 05\n  05 --&gt; 06\n  02 --&gt; 06\n  06 --&gt; 07 \n\n\n  style 00 fill:#C5E6A1,stroke-width:0px\n  style 01 fill:#C5E6A1,stroke-width:0px\n  style 02 fill:#C5E6A1,stroke-width:0px\n  style 03 fill:#C5E6A1,stroke-width:0px\n  style 04 fill:#C5E6A1,stroke-width:0px\n  style 05 fill:#C5E6A1,stroke-width:0px\n  style 06 fill:#E1C3E6,stroke-width:0px\n  style 07 fill:#E6DEA100,stroke-width:0px\n\n</code></pre> <p></p>"},{"location":"challenges-wb/extract-streams/#tour-of-outputs","title":"Tour of outputs","text":"<p>The video tours the output layers from this model in QGIS.  </p>"},{"location":"challenges-wb/least-cost-path/","title":"least cost path practice","text":""},{"location":"challenges-wb/least-cost-path/#problem","title":"Problem","text":"<p>Please write a python script that uses whitebox tools to find the least cost path from BiHall to the Knoll. </p> <p>Please use the base_land_cover.tif from the GEE export example for the land cover input. And use the \u201cod_lcp_practice.tif\u201d on the shared DATA/od/ directory for the origin-destination input.  </p> <p>You will need to derive the friction values for the land cover reclass on your own. Try to assign values so that the least cost path that results resembles the one that you would take if you were to walk from the back of BiHall to the Knoll. Please know that all pixels must have some cost that accumulates (so make the lowest friction 1 rather than 0). Also remember that the whitebox reclass operation requires a string of \u201cnew value;old value\u201d pairs. So you will need to adapt the string below by replacing the \u2018x#\u2019 with a cost associated with the following land cover class:  </p> <pre><code>\"x1;1;x2;2;x3;3;x4;4;x5;5;x6;6;x7;7;x8;8\"\n</code></pre>"},{"location":"challenges-wb/least-cost-path/#workflow","title":"Workflow","text":"<p> <pre><code>graph TD\n\n  00((origin-destination)) ;\n  01[EqualTo] ;\n  02[EqualTo] ;\n  03((land-cover)) ;\n  04[Reclass] ;\n  05[CostDistance] ;\n  06[CostPathway] ;\n  07((&amp;#128526)) ;\n\n  00 --&gt; 01 ;\n  00 --&gt; 02 ;\n  03 --&gt; 04 ;\n  01 --&gt; 05 ;\n  04 --&gt; 05 ;\n  02 --&gt; 06 ;\n  05 --&gt; 06 ;\n  06 --&gt; 07 ; \n\n\n  style 00 fill:#C5E6A1,stroke-width:0px\n  style 01 fill:#C5E6A1,stroke-width:0px\n  style 02 fill:#C5E6A1,stroke-width:0px\n  style 03 fill:#C5E6A1,stroke-width:0px\n  style 04 fill:#C5E6A1,stroke-width:0px\n  style 05 fill:#C5E6A1,stroke-width:0px\n  style 06 fill:#C5E6A1,stroke-width:0px\n  style 07 fill:#E6DEA100,stroke-width:0px\n\n</code></pre> <p></p>"},{"location":"challenges-wb/least-cost-path/#tour-of-outputs","title":"Tour of outputs","text":"<p>The video below tours the input and output layers from this model in QGIS.  </p>"},{"location":"challenges-wb/viewshed-comparison/","title":"viewshed comparison from dem and dsm","text":""},{"location":"challenges-wb/viewshed-comparison/#problem","title":"Problem","text":"<p>Please write a python script that uses Whitebox tools to compare visibility computed from a DEM and DSM for a single viewpoint. Please use the \u201cdem_clipped_practice.tif\u201d and \u201cdsm_clipped_practice.tif files from the vermont lidar tutorial. Please use the \u2018knoll.shp\u2019 file from the shared DATA/view-points/ directory. </p> <p>Please note that the two surface images (DEM and DSM) have a minor difference in extent which complicates the workflow. To understand why we need to do the Resample step in this problem, please refer to the mama raster page. </p>"},{"location":"challenges-wb/viewshed-comparison/#workflow","title":"Workflow","text":"<p> <pre><code>graph TD\n\n  00((DEM)) ;\n  01((view-point)) ;\n  03[Viewshed] ;\n  02((DSM)) ;\n  04[Viewshed] ;\n  05[Resample] ;\n  06[Multiply] ;\n  07[Add] ;\n  08((&amp;#128526)) ;\n\n  00 --&gt; 03 ;\n  01 --&gt; 03 ;\n  01 --&gt; 04 ;\n  02 --&gt; 04 ;\n  03 --&gt; 05 ;  \n  04 --&gt; 05 ;\n  05 --&gt; 06 ;\n  03 --&gt; 07 ;\n  06 --&gt; 07 ;\n  07 --&gt; 08 ;\n\n  style 00 fill:#C5E6A1,stroke-width:0px\n  style 01 fill:#E1C3E6,stroke-width:0px\n  style 02 fill:#C5E6A1,stroke-width:0px\n  style 03 fill:#C5E6A1,stroke-width:0px\n  style 04 fill:#C5E6A1,stroke-width:0px\n  style 05 fill:#C5E6A1,stroke-width:0px\n  style 06 fill:#C5E6A1,stroke-width:0px\n  style 07 fill:#C5E6A1,stroke-width:0px\n  style 08 fill:#E6DEA100,stroke-width:0px\n\n</code></pre> <p></p>"},{"location":"challenges-wb/viewshed-comparison/#tour-of-outputs","title":"Tour of outputs","text":"<p>The video below tours the input and output layers from this model in QGIS. </p>"},{"location":"challenges-wb/workflow-diagrams/","title":"workflow diagrams","text":"<p>Workflow diagrams show how each step in a solution connects to other steps. The color represents the format of the result (or output) of each step as shown below.  </p> <p> <pre><code>graph TD\n  raster[raster] ;\n  vector[vector] ;\n\nstyle raster fill:#C5E6A1,stroke-width:0px\nstyle vector fill:#E1C3E6,stroke-width:0px</code></pre> <p></p> <p>Links between steps show how the output of one step serves as the input to another.      </p> <p> <pre><code>graph LR\n  step01[Step 1] ;\n  step02[Step 2] ;\n\n  step01 --&gt; step02 \n\n  style step01 fill:#C5E6A1,stroke-width:0px\n  style step02 fill:#E1C3E6,stroke-width:0px\n\n</code></pre> <p></p> <p>Shape distinguishes data objects and operations. The example below takes a vector and raster object as inputs and outputs a raster.       </p> <p> <pre><code>graph LR\n\n  01((raster object)) ;\n  02((vector object))\n  03[operation] ;\n\n  01 --&gt; 03 \n  02 --&gt; 03\n\n  style 01 fill:#C5E6A1,stroke-width:0px\n  style 02 fill:#E1C3E6,stroke-width:0px\n  style 03 fill:#C5E6A1,stroke-width:0px\n</code></pre> <p></p>"},{"location":"concepts/change/","title":"change concepts","text":"<p>The purpose of planning is to inform and influence changes on the land. As such, planning with maps relies on cartographic models for representing spatial change.  </p>"},{"location":"concepts/change/#evolution-of-a-single-entity","title":"evolution of a single entity","text":""},{"location":"concepts/change/#basic-changes","title":"basic changes","text":"<p>appearance, disappearance, stability  </p>"},{"location":"concepts/change/#transformations","title":"transformations","text":"<p>expansion, contraction, deformation   </p>"},{"location":"concepts/change/#movements","title":"movements","text":"<p>translation, rotation  </p>"},{"location":"concepts/change/#processes","title":"processes","text":""},{"location":"concepts/change/#replacement","title":"replacement","text":"<p>succession, permutation  </p>"},{"location":"concepts/change/#diffusion","title":"diffusion","text":"<p>production, reproduction,  transmission  </p>"},{"location":"concepts/change/#restructuring","title":"restructuring","text":"<p>split, union, re-allocation  </p>"},{"location":"concepts/data-models/","title":"data models","text":"<p>Geographical data models are frameworks for storing geographic data within the constraints of computer architectures. They are general templates. Some are specific to individual software platforms, while others are shared across packages and follow general conventions or standards.  </p>"},{"location":"concepts/data-models/#cartographic-model","title":"cartographic model","text":"<p>Tomlin (1990/2012)      </p>"},{"location":"concepts/data-models/#layer","title":"layer","text":"<p>title, metadata, zone(s)  </p>"},{"location":"concepts/data-models/#zone","title":"zone","text":"<p>label, value, location  </p>"},{"location":"concepts/data-models/#value","title":"value","text":"<p>nominal, ordinal, interval, ratio, cyclical, null</p>"},{"location":"concepts/data-models/#location","title":"location","text":"<p>a finite portion of the plane; grid, cell, resolution  </p>"},{"location":"concepts/data-models/#neighborhood","title":"neighborhood","text":"<p>focus, distance  </p>"},{"location":"concepts/data-models/#characteristic","title":"characteristic","text":"<p>punctual, lineal, areal, surficial   </p>"},{"location":"concepts/data-models/#geographic-frameworks","title":"geographic frameworks","text":""},{"location":"concepts/data-models/#coordinate-reference-system-crs","title":"coordinate reference system (CRS)","text":""},{"location":"concepts/data-models/#vector","title":"vector","text":""},{"location":"concepts/data-models/#geometry","title":"geometry","text":""},{"location":"concepts/data-models/#attribute","title":"attribute","text":""},{"location":"concepts/data-models/#feature","title":"feature","text":""},{"location":"concepts/data-models/#collection-table","title":"collection (table)","text":""},{"location":"concepts/data-models/#raster-image","title":"raster image","text":""},{"location":"concepts/data-models/#band","title":"band","text":""},{"location":"concepts/data-models/#image","title":"image","text":""},{"location":"concepts/data-models/#collection","title":"collection","text":""},{"location":"concepts/data-models/#image-collection","title":"image collection","text":""},{"location":"concepts/data-models/#temporal","title":"temporal","text":""},{"location":"concepts/planning/","title":"planning concepts","text":"<p>Applied geographers believe that people should have good reasons for locating things where they do and parallels the goals of planning professions.  </p> <p>This section lists general concepts from site planning and conservation planning domains that often inform applications of cartographic modeling.         </p>"},{"location":"concepts/planning/#site","title":"site","text":""},{"location":"concepts/planning/#as-system","title":"as system","text":""},{"location":"concepts/planning/#for-purpose","title":"for purpose","text":""},{"location":"concepts/planning/#behavior-settings","title":"behavior settings","text":""},{"location":"concepts/planning/#behavior-programs","title":"behavior programs","text":""},{"location":"concepts/planning/#levels","title":"levels","text":""},{"location":"concepts/planning/#landscape","title":"landscape","text":""},{"location":"concepts/planning/#community","title":"community","text":""},{"location":"concepts/planning/#habitat","title":"habitat","text":""},{"location":"concepts/planning/#species","title":"species","text":""},{"location":"concepts/planning/#conditions","title":"conditions","text":""},{"location":"concepts/planning/#diversity","title":"diversity","text":""},{"location":"concepts/planning/#fragmentation","title":"fragmentation","text":""},{"location":"concepts/planning/#connectivity","title":"connectivity","text":""},{"location":"concepts/planning/#representative","title":"representative","text":""},{"location":"concepts/planning/#rarity","title":"rarity","text":""},{"location":"concepts/spatial/","title":"spatial concepts","text":"<p>Geographers aim to understand why things are located where they are. These questions build on the primitive concepts of a location with one or more conditions (also called values, attributes, or properties).  </p>"},{"location":"concepts/spatial/#analytical-skills","title":"analytical skills","text":"<p>Gersmehl (2005: 97-111) </p>"},{"location":"concepts/spatial/#location","title":"location","text":"<p>Where is it?   </p>"},{"location":"concepts/spatial/#conditions","title":"conditions","text":"<p>What is there? </p>"},{"location":"concepts/spatial/#connections","title":"connections","text":"<p>How are conditions at one location linked with conditions at other places?  </p>"},{"location":"concepts/spatial/#comparison","title":"comparison","text":"<p>How are conditions at one location similar or different to conditions at other places?    </p>"},{"location":"concepts/spatial/#aura","title":"aura","text":"<p>How do conditions at one location influence nearby places?    </p>"},{"location":"concepts/spatial/#region","title":"region","text":"<p>What places are similar to each other and can be grouped together?_  </p>"},{"location":"concepts/spatial/#hierarchy","title":"hierarchy","text":"<p>Where does this place fit in a hierarchy of places?  </p>"},{"location":"concepts/spatial/#transition","title":"transition","text":"<p>How do conditions change between two places?  </p>"},{"location":"concepts/spatial/#analog","title":"analog","text":"<p>What distant places have similar conditions to this place?      </p>"},{"location":"concepts/spatial/#patterns","title":"patterns","text":"<p>How are conditions arranged in imbalances, clusters, strings, rings, or other non-random ways?  </p>"},{"location":"concepts/spatial/#associations","title":"associations","text":"<p>What conditions tend to occur together?  </p>"},{"location":"concepts/spatial/#exceptions","title":"exceptions","text":"<p>Where are places that do not fit the rule?   </p>"},{"location":"methods/aggregate-table/","title":"aggregate table","text":""},{"location":"methods/aggregate-table/#sum-the-values-in-a-table-column","title":"sum the values in a table column","text":"<pre><code>// -------------------------------------------------------------\n//  SUM THE VALUES IN A TABLE COLUMN (FC PROPERTY) \n\n//  Input must be a feature collection.\n//  Replace 'PROPERTY' with the property name (STRING) to sum.  \n//  Output is a number object.\n// -------------------------------------------------------------\n</code></pre> <pre><code>var answer = input.aggregate_sum('PROPERTY');\n\n// Print results to console.  \n\nprint(\n'ANSWER',\nanswer,                 //  This will report the answer with eleven decimal places.\nanswer.round()          //  This will round to nearest integer.\n);\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"methods/aggregate-table/#dissolve-features-in-collection-by-property","title":"dissolve features in collection by property","text":"<pre><code>// -------------------------------------------------------------\n//  DISSOLVE FEATURES IN COLLECTION BY PROPERTY. \n\n//  Input must be a feature collection.\n//  Replace 'PROPERTY' with the property name to dissolve features.  \n//  Output is a feature collection (with singlepart and multipart features),\n//  where each feature represents the region of a unique property value. \n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = t.dissolveByProperty(input, 'PROPERTY');\n\n// -------------------------------------------------------------\n</code></pre> <p>You can access the underlying code for this function in the tasks module. </p>"},{"location":"methods/aggregate-table/#practical-tip","title":"practical tip","text":"<p>If you would like to dissolve all features in a collection (produce one multipart feature from a collection) without distinguishing subclasses based on a property in the function, then first run this snippet to add a property to all features that holds the same value.</p> <pre><code>//  Give all features in collection a new property with the same value. \n\nvar prep = input.map(function(f){return f.set('tag', 1)});  </code></pre> <p>Then use <code>prep</code> as input and <code>'tag'</code> as property.    </p>"},{"location":"methods/area/","title":"area operations","text":""},{"location":"methods/area/#acres-of-each-feature-in-collection","title":"acres of each feature in collection","text":"<pre><code>// -------------------------------------------------------------\n//  CALCULATE AREA (ACRES) OF FEATURES IN COLLECTION. \n// -------------------------------------------------------------\n\n//  This CRS is good for Vermont. Replace if you work elsewhere.\n\nvar crs = \"EPSG:32145\";\n\n//  Input must be a feature collection.\n//  Output is a feature collection.\n//  Each output feature has new property 'acres' that holds the area of feature.\n//  Replace 'acres' with something else to define an alternative property name. \n//  Remember to following naming rules for properties. \n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = input\n.map(t.howManyAcres(crs, 'acres'))\n;\n\n// -------------------------------------------------------------\n</code></pre> <p>You can access the underlying code for this function in the tasks module. </p>"},{"location":"methods/area/#sq-km-of-each-features-in-collection","title":"sq km of each features in collection","text":"<pre><code>// -------------------------------------------------------------\n//  CALCULATE AREA (SQUARE KM) OF FEATURES IN COLLECTION. \n// -------------------------------------------------------------\n\n//  This CRS is good for Vermont. Replace if you work elsewhere.\n\nvar crs = \"EPSG:32145\";\n\n//  Input must be a feature collection.\n//  Output is a feature collection.\n//  Each output feature has new property 'sq_km' that holds the area of feature.\n//  Replace 'sq_km' with something else to define an alternative property name.  \n//  Remember to following naming rules for properties (no spaces).\n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = input\n.map(t.howManySqKm(crs, 'sq_km'))\n;\n\n// -------------------------------------------------------------\n</code></pre> <p>You can access the underlying code for this function in the tasks module. </p>"},{"location":"methods/area/#make-pixel-area-image","title":"make pixel area image","text":"<pre><code>// -------------------------------------------------------------\n//  MAKE PIXEL AREA IMAGE.\n\n//  Returns an image with values that represent pixel area in acres. \n//  Modify second line to alter units. \n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = ee.Image.pixelArea()\n.divide(4046.86)                  // converts to acres\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"methods/convert-data-model/","title":"convert data model","text":""},{"location":"methods/convert-data-model/#feature-collection-to-binary-image","title":"feature collection to binary image","text":"<pre><code>// -------------------------------------------------------------\n//  CONVERT FEATURE COLLECTION TO BINARY IMAGE. \n\n//  INPUT must be a feature collection.\n//  OUTPUT will be a binary raster.  \n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = t.fc2Binary(input);\n\n// -------------------------------------------------------------\n</code></pre> <p>You can access the underlying code for this function in the tasks module. </p>"},{"location":"methods/convert-data-model/#mosaic-image-collection-to-image","title":"mosaic image collection to image","text":"<pre><code>// -------------------------------------------------------------\n//  MOSAIC IMAGE COLLECTION   \n\n//  INPUT must be an image collection with a 'quilt patch' structure.\n//  OUTPUT will be a image with a 'quilted' structure.  \n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = input.mosaic();\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"methods/convert-data-model/#image-to-rgb","title":"image to rgb","text":"<pre><code>// -------------------------------------------------------------------------\n//  IMAGE TO RGB  \n\n//  INPUT is an image.\n//  min, max, gamma, etc are should call viz parameters\n//  OUTPUT is three band (RGB) image. \n// -------------------------------------------------------------------------\n</code></pre> <pre><code>var output_rgb = input.visualize({\nmin: viz.min, max: viz.max, gamma: viz.gamma,\nforceRgbOutput: true\n});\n</code></pre>"},{"location":"methods/distance/","title":"distance operations","text":""},{"location":"methods/distance/#buffer-features-in-collection-by-feet","title":"buffer features in collection by feet","text":"<pre><code>// -------------------------------------------------------------\n//  BUFFER FEATURES IN COLLECTION BY FEET.\n\n//  INPUT is a feature collection. \n//  DISTANCE is a number in units feet.\n//  OUTPUT is a single part feature collection of polygons. \n// -------------------------------------------------------------\n</code></pre> <pre><code>var OUTPUT = INPUT.map(t.bufferFeet(DISTANCE));\n\n// -------------------------------------------------------------\n</code></pre> <p>You can access the underlying code for this function in the tasks module. </p>"},{"location":"methods/distance/#euclidean-distance-image","title":"euclidean distance image","text":"<p><pre><code>// -----------------------------------------------------------------------------\n//  EUCLIDEAN DISTANCE\n//\n//  euc_distance output represents the euclidean distance to the nearest non-zero pixel of input.\n//  Input must be image with 0 as background value.\n// -----------------------------------------------------------------------------\n</code></pre> <pre><code>var crs = \"EPSG:32145\";\nvar kr = 100;                   // Diameter of kernel, or zone to compute distance over. \n\nvar euc_distance = input\n.distance(ee.Kernel.euclidean({radius: kr, units: 'meters'}))\n.reproject({crs: crs})       // This can slow down analysis, especially over large extents.                                   \n.rename('distance')\n;\n\n// Fun palette for distance images. \n\nvar inferno = [\"#000004\", \"#320A5A\", \"#781B6C\", \"#BB3654\", \"#EC6824\", \"#FBB41A\", \"#FCFFA4\"].reverse();\n\n// Add layer to map with fun palette. \n\nMap.addLayer(euc_distance,  {min:0, max: 100, palette: inferno}, \"Euclidean distance image\", false);\n\n// -------------------------------------------------------------\n</code></pre></p>"},{"location":"methods/distance/#practical-tip-for-crs","title":"practical tip for crs","text":"<p>The <code>.reproject({crs: crs})</code> line allows you to force earth engine to calculate distance in a specified coordinate system. Without this, ee will compute distance with web mercator and the distance measurement will not be accurate. With this, it can slow down the computation because ee essentially has to make a new image and then make the calculation on it.  </p> <p>One strategy then is to comment out the crs line when you are drafting your script to speed up visualizing and checking your work. If you do this, you will need to remember to uncomment the line when you are producing final results.  </p>"},{"location":"methods/export/","title":"export to drive","text":"<p>The following three code blocks together provide a template for exporting objects from Earth Engine scripts to your personal google drive so that you can use these data in whitebox or other gis platforms.  </p>"},{"location":"methods/export/#load-example-object","title":"Load example object","text":"<p>In this example, we first load a polygon geometry object. This represents a test study region that I use in many of the whitebox tutorials. </p> <pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Exporting template  \n\n//  Last modified: 3/22/2024 \n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n// -------------------------------------------------------------\n//  LOAD DATA MODULE. \n// -------------------------------------------------------------\n\nvar data = require('users/jhowarth/public:modules/data.js');       print('DATA', data);\n\n// -------------------------------------------------------------\n//  DEFINE KEY TERMS\n// -------------------------------------------------------------\n\nvar crs = \"EPSG:32145\";\nvar xfolder = 'x0352';\n\nvar scale = 1.5;\nvar transform = [scale, 0, 0, 0, scale, 0];\n\n// -------------------------------------------------------------\n//  DEFINE GEOMETRY OBJECT\n//\n//  I used the drawing tools to make this polygon and then pasted\n//  the coordinates here so that we could all have the same object.\n// -------------------------------------------------------------\n\nvar geometry = ee.Geometry.Polygon(\n[[[-73.22494136517258, 44.03630018203328],\n[-73.22494136517258, 44.001612587825356],\n[-73.13190089886399, 44.001612587825356],\n[-73.13190089886399, 44.03630018203328]]], null, false);\n\nMap.centerObject(geometry, 13);\nMap.setOptions('hybrid');\n\nMap.addLayer(geometry, {color: 'red'}, \"Geometry object\", false);\n\n// -------------------------------------------------------------\n//  DEFINE A NOMINAL IMAGE \n// -------------------------------------------------------------\n\n//  Reproject nominal image into desired scale and coordinate system.\n\nvar image = ee.Image(data.lc.base.i)\n;\n\n//  View as a layer. \n\nMap.addLayer(image, data.lc.base.viz, \"Base land cover\", false);\n</code></pre>"},{"location":"methods/export/#export-geometry-object-to-drive","title":"Export geometry object to drive","text":"<p>The code block below will exports the geometry object defined above to a folder in your google drive called \u2018x0352\u2019. If this folder does not exist, earth engine will make it at the root level.  </p> <pre><code>// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n//  EXPORT GEOMETRY OBJECT \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n//  Reproject geometry object into desired coordinate system.\n\nvar geo_projected = geometry.transform(crs, 1);\n\n//  Cast geometry as a feature collection. \n\nvar geo_fc = ee.FeatureCollection(geo_projected);\n\n//  Define name for export object and task\n\nvar geo_name = 'geo_object_example';\n\n//  Export to drive\n\nExport.table.toDrive(\n{\ncollection: geo_fc, description: geo_name, folder: xfolder, fileNamePrefix: geo_name, fileFormat: 'SHP', // selectors, maxVertices, priority\n}\n);\n</code></pre>"},{"location":"methods/export/#export-nominal-raster","title":"Export nominal raster","text":"<p>The code block below will export the nominal image from above to your google drive. Please note that the export dictionary requires a region that will clip the exported image. In this example, we use the test region polygon for this purpose.  </p> <pre><code>// -------------------------------------------------------------\n//  EXPORT A NOMINAL IMAGE \n// -------------------------------------------------------------\n\n//  Reproject nominal image into desired scale and coordinate system.\n\nvar image_projected = ee.Image(data.lc.base.i)\n.reproject(crs, [scale, 0, 0, 0, scale , 0])\n.byte()\n;\n\n//  Define name for task and image. \n\nvar task = 'base_land_cover';       // 03/29/24\n\n//  Export image to drive.\n\nExport.image.toDrive(\n{\nimage: image_projected, description: task, folder: xfolder, fileNamePrefix: task, // dimensions, \nregion: geo_projected, // scale, \ncrs: crs, crsTransform: transform, maxPixels: 1e12, // shardSize, \n// fileDimensions, \n// skipEmptyTiles, \nfileFormat: 'GeoTIFF', // formatOptions, \n// priority\n\n}\n);\n</code></pre>"},{"location":"methods/filter-data/","title":"filter data","text":""},{"location":"methods/filter-data/#by-attribute","title":"by attribute","text":"<pre><code>// -------------------------------------------------------------\n//  FILTER COLLECTION BY ATTRIBUTE. \n\n//  Input must be a collection.\n//  Output is a collection, where each object in collection satisfies criterion.\n\n//  Set CRITERION (see options in ee.Filter docs).\n//  Set \"property_name\".\n//  Set \"value\".\n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = input\n.filter(ee.Filter.CRITERION(\"property_name\", \"value\"))\n;\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"methods/filter-data/#by-bounds","title":"by bounds","text":"<pre><code>// -------------------------------------------------------------\n//  FILTER COLLECTION BY REGION. \n\n//  Input must be a feature collection.\n//  BOUNDS may be a point, line, or polygon geometry, feature, or feature collection.\n//  Output is a collection, where each object intersects.\n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = input\n.filterBounds(BOUNDS)\n;\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"methods/filter-data/#select-image-band","title":"select image band","text":"<pre><code>// -------------------------------------------------------------\n//  SELECT IMAGE BAND. \n\n//  Input must be an image or image collection.\n//  'Band_name' is name of band as a string or list of bands (list of strings).\n//  Output is same data type as input. \n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = input\n.select('band_name')\n;\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"methods/image-viz/","title":"viz","text":""},{"location":"methods/image-viz/#make-histogram-of-image-values","title":"make histogram of image values","text":"<pre><code>// Make a viz dictionary.\n\nvar input_viz = {\nmin: [0,0,0],                       // List of min in same order as band list.\nmax: [255,255,255],                 // List of max in same order as band list.\nbands: ['R', 'G', 'B']              // In this example, R is index 0, G is index 1, and B is index 2.\n};\n\n// Make a histogram to see data distribution.  \n\nvar b = 0;                            // This targets a band number by the list index. 0 will target R.\nvar i = INPUT;                        // This targets an image. Replace IMAGE with image variable.\nvar v = input_viz;                    // This targets the viz parameters for the image.\n\nvar histogram = t.makeHistogram(\ni,                                  // Must be an image (not an image collection).\nv.bands[b],                         // Select one band at a time.\n3,                                  // Pixel resolution of image.\nv.min[b],                           // Minimum value of x-axis\nv.max[b]                            // Maximum value of x-axis.\n)\n;\n\n// Print, print, print...\n\nprint(\n\"HISTOGRAM\", histogram\n)\n;\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"methods/image-viz/#print-min-and-max-of-an-image","title":"Print min and max of an image","text":"<pre><code>// -------------------------------------------------------------\n//  PRINT MIN AND MAX OF AN IMAGE \n\n//  IMAGE must be, well, an image... \n//  REGION must be a feature collection or feature that define study region.\n//  SCALE is pixel scale of request; the function will run faster if request a lower resolution.\n//  LABEL to print as a header in Console (must be a string). \n\n// -------------------------------------------------------------\n</code></pre> <pre><code>t.printImageRange(image, region, scale, label);\n</code></pre> <p>Please note: you do not need to store the output of this function as a variable. You just need to run the function with your desired arguments and a dictionary with the min/max values will be printed to the Console.  </p> <p>You can access the underlying code for this function in the tasks module.   </p>"},{"location":"methods/image-viz/#viz-with-gamma-to-influence-midtones","title":"Viz with gamma to influence midtones","text":"<pre><code>// -------------------------------------------------------------\n//  VIZ WITH GAMMA TO INFLUENCE MIDTONES\n//\n//  A gamma &gt; 1 will lighten midtones.\n//  A gamma &lt; 1 will darken midtones. \n// -------------------------------------------------------------\n\nvar viz = {\n\nmin: 0, max: 255,\ngamma: 1.5\n\n}\n;\n</code></pre>"},{"location":"methods/image-viz/#blend-two-images","title":"Blend two images","text":"<pre><code>// -------------------------------------------------------------\n//  BLEND TWO IMAGES\n\n//  Thanks to Jesse Anderson's gee-blend module. \n//  https://github.com/jessjaco/gee-blend\n\n//  These are similar to Photoshop overlay techniques.  \n//  It is often more effective to blend two images than try \n//  to visually combine them by lowering the opacity of one layer.  \n// -------------------------------------------------------------\n</code></pre> <pre><code>var blend = require('users/jja/public:blend.js');\n\nvar output = blend.multiply(rgb1, rgb2);          // See gee-blend docs for other blend options besides multiply.  \n\nMap.addLayer(output, {}, \"RGB1 and RGB2 blend\");\n\n// -------------------------------------------------------------\n</code></pre> <p>Read the gee-blend docs to learn more about this useful module for cartography with ee.  </p>"},{"location":"methods/inspect-properties/","title":"inspect properties","text":""},{"location":"methods/inspect-properties/#print-first-feature-in-fc","title":"print first feature in FC","text":"<pre><code>// -------------------------------------------------------------\n//  PRINT FIRST FEATURE IN COLLECTION.  \n\n//  Replace 'LABEL' with appropriate header.  \n//  Replace fc with appropriate variable.\n// -------------------------------------------------------------\n</code></pre> <pre><code>print(\n\"LABEL\",\nfc.first()\n)\n;\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"methods/inspect-properties/#print-unique-values-in-fc","title":"print unique values in FC","text":"<pre><code>// -------------------------------------------------------------\n//  PRINT UNIQUE VALUES OF FEATURE PROPERTY IN COLLECTION. \n\n//  Replace 'LABEL' with appropriate header.  \n//  Replace fc with appropriate variable.\n// -------------------------------------------------------------\n</code></pre> <pre><code>print(\n\"LABEL\",\nfc.aggregate_array().distinct().sort()\n)\n;\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"methods/inspect-properties/#print-size-of-collection","title":"print size of collection","text":"<pre><code>// -------------------------------------------------------------\n//  PRINT SIZE OF COLLECTION. \n\n//  Replace 'LABEL' with appropriate header.  \n//  Replace collection with appropriate variable.\n// -------------------------------------------------------------\n</code></pre> <pre><code>print(\n\"LABEL\",\ncollection.size()\n)\n;\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"methods/intro/","title":"introduction","text":"<p>This is a collection of recurring tasks that can be implemented with the javascript code editor for Google Earth Engine.  </p> <p>In many cases, the snippets use data and tools that are shared via my public earth engine repo. Click here to add the repository to the \u201cReader\u201d section in your instance of Code Editor. This will allow you to see the underlying code.  </p>"},{"location":"methods/load-data/","title":"load data","text":""},{"location":"methods/load-data/#feature-collection-from-address","title":"feature collection from address","text":"<pre><code>// -------------------------------------------------------------\n//  LOAD FEATURE COLLECTION FROM ADDRESS. \n\n//  Replace LAYER with a key from the data repo;\n//  or replace argument with EE address string. \n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = ee.FeatureCollection(data.LAYER.fc_address);\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"methods/load-data/#image-collection-from-address","title":"image collection from address","text":"<pre><code>// -------------------------------------------------------------\n//  LOAD IMAGE COLLECTION FROM ADDRESS. \n\n//  Replace LAYER with a key from the data repo;\n//  or replace argument with EE address string.\n// -------------------------------------------------------------  \n</code></pre> <pre><code>var output = ee.ImageCollection(data.LAYER.ic);\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"methods/load-data/#image-from-address","title":"image from address","text":"<pre><code>// -------------------------------------------------------------\n//  LOAD IMAGE FROM ADDRESS. \n\n//  Replace LAYER with a key from the data repo;\n//  or replace argument with EE address string.\n// -------------------------------------------------------------  \n</code></pre> <pre><code>var output = ee.Image(data.LAYER.i);\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"methods/load-modules/","title":"load modules","text":""},{"location":"methods/load-modules/#data-module","title":"data module","text":"<pre><code>// -------------------------------------------------------------\n//  LOAD DATA MODULE. \n// -------------------------------------------------------------\n\nvar data = require('users/jhowarth/public:modules/data.js');       print('DATA', data);\n</code></pre>"},{"location":"methods/load-modules/#tasks-module","title":"tasks module","text":"<pre><code>// -------------------------------------------------------------\n//  LOAD TASKS MODULE. \n// -------------------------------------------------------------\n\nvar t = require('users/jhowarth/public:modules/tasks.js');\n</code></pre>"},{"location":"methods/load-modules/#layout-module","title":"layout module","text":"<pre><code>// -------------------------------------------------------------\n//  LOAD LAYOUT MODULE. \n// -------------------------------------------------------------\n\nvar layout = require('users/jhowarth/public:modules/layout.js').layout;\nprint('LAYOUT', layout);\n</code></pre>"},{"location":"methods/local-one-layer/","title":"local - one layer","text":""},{"location":"methods/local-one-layer/#reclassify-nominal-values","title":"reclassify nominal values","text":"<pre><code>// -------------------------------------------------------------\n//  RECLASSIFY VALUES AT LOCATIONS.\n\n//  INPUT is an image with values to reclassify;\n//  from key holds list of values in input image,\n//  to key holds a list of new values, where the list index\n//  determines the from --&gt; to reclassification.\n//  'BAND_NAME' is name of band to reclassify (default is first band).\n//  OUTPUT is name for new reclassified image. \n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = input.remap(\n{\nfrom: [0,1,2,3,4],\nto:   [0,0,1,0,1],\nbandName: 'band_name'\n}\n\n); // -------------------------------------------------------------\n</code></pre>"},{"location":"methods/local-one-layer/#classify-image-by-equal-interval","title":"classify image by equal interval","text":"<pre><code>// -------------------------------------------------------------\n//  CLASSIFY AN IMAGE BY AN EQUAL INTERVAL\n\n//  INPUT is an image with continuous values (like a DEM).\n//  INTERVAL is an integer that defines equal interval of scheme. \n\n//  OUTPUT is an image, where values represent quotient as integer;\n//    input = dividend, \n//    interval = divisor,  \n//    remainder is ignored.\n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = input.divide(interval).ceil();\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"methods/local-one-layer/#threshold-an-image","title":"threshold an image","text":"<pre><code>// -------------------------------------------------------------\n//  THRESHOLD AN IMAGE\n\n//  INPUT is an image with values to convert to binary.\n//  THRESHOLD is placeholder for criterion operator:\n\n//    .eq() --&gt; equals\n//    .lt() --&gt; less than \n//    .gt() --&gt; greater than\n//    etc. \n//\n//  OUTPUT is binary, where all pixels that satisfy criterion are 1\n//  and all other pixels are 0. \n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = input.THRESHOLD(VALUE); // -------------------------------------------------------------\n</code></pre>"},{"location":"methods/local-one-layer/#multiply-image-by-constant","title":"multiply image by constant","text":"<pre><code>// -------------------------------------------------------------\n//  MULTIPLY IMAGE LAYER BY CONSTANT\n\n//  i1 is an image.\n//  c is constant.\n//  output is an image.\n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = i1.multiply(c);\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"methods/local-two-layers/","title":"local - two layers","text":""},{"location":"methods/local-two-layers/#maximum-at-locations","title":"maximum at locations","text":"<pre><code>// -------------------------------------------------------------\n//  MAXIMUM AT LOCATIONS\n\n//  This operation does pairwise comparisons of pixel values between\n//  two images (i1, i2); the output stores the maximum of each pair. \n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = i1.max(i2);\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"methods/local-two-layers/#minimum-at-locations","title":"minimum at locations","text":"<pre><code>// -------------------------------------------------------------\n//  MINIMUM AT LOCATIONS\n\n//  This operation does pairwise comparisons of pixel values between\n//  two images (i1, i2); the output stores the minimum of each pair. \n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = i1.min(i2);\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"methods/local-two-layers/#intersect-two-binaries","title":"intersect two binaries","text":"<pre><code>// -------------------------------------------------------------\n//  INTERSECT TWO BINARIES.\n\n//  i1 and i2 are both binary images {0,1}.\n//  output is a binary image {0,1}.\n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = i1.and(i2);\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"methods/local-two-layers/#erase-values-at-locations-with-binary","title":"erase values at locations with binary","text":"<pre><code>// -------------------------------------------------------------\n//  ERASE VALUES AT LOCATIONS WITH BINARY.\n\n//  INPUT is an image with values to erase.\n//  BINARY is a binary image {0,1}.\n//  OE (output erased) is an image. \n// -------------------------------------------------------------\n</code></pre> <pre><code>var oe = input\n.multiply(binary)\n;\n\nprint(\n\"ERASED\",\noe\n)\n;\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"methods/local-two-layers/#mask-values-at-locations","title":"mask values at locations","text":"<pre><code>// -------------------------------------------------------------\n//  MASK VALUES AT LOCATIONS .\n\n//  INPUT is an image with values to mask.\n//  MASK is an image with zero and non-zero values.\n//  OUTPUT is same as input except all zero values in MASK are masked\n// -------------------------------------------------------------\n</code></pre> <p>```js</p> <p>var output = input.updateMask(mask) ;</p> <p>// -------------------------------------------------------------</p>"},{"location":"methods/map-layers/","title":"map layers","text":""},{"location":"methods/map-layers/#viz-for-raster","title":"viz for raster","text":"<p><pre><code>// -------------------------------------------------------------\n//  VIZ PARAMETERS FOR RASTER DATA\n\n//  Replace VIZ with custom name.\n//  Adjust BAND_NAME to define band or list of bands to display. \n//  Adjust min value to minimum value displayed with color.\n//  Adjust max value to maximum value displayed with color.\n//  Adjust gamma to brighten or darken midtones.\n//  Min, max, gamma can be custom for each band from list order.\n</code></pre> <pre><code>// -------------------------------------------------------------\n\nvar VIZ = {\nbands: ['BAND_NAME'],\nmin: [0],\nmax: [255],\ngamma: [1]\n}\n;\n\n// -------------------------------------------------------------\n</code></pre></p>"},{"location":"methods/map-layers/#simple-viz-for-vector","title":"simple viz for vector","text":"<p><pre><code>// -------------------------------------------------------------\n//  SIMPLE VIZ PARAMETERS FOR VECTOR DATA\n\n//  Replace VIZ with custom name.\n//  Adjust COLOR with HTML color name or hex code.\n\n//  RESOURCE: https://htmlcolorcodes.com/color-names/\n</code></pre> <pre><code>// -------------------------------------------------------------\n\nvar VIZ = {\ncolor: 'Orchid'\n}\n;\n\n// -------------------------------------------------------------\n</code></pre></p>"},{"location":"methods/map-layers/#add-layer","title":"add layer","text":"<p><pre><code>// -------------------------------------------------------------\n//  ADD LAYER TO MAP\n\n//  Replace DATA with name of collection, image, geometry.\n//  Replace VIZ with parameters for vector or raster data.  \n//  Replace LAYER_NAME with name as a string.\n//  Change FALSE to true to show by default.\n//  Change 1 to decimal between 0 and 1 to adjust opacity.\n</code></pre> <pre><code>// -------------------------------------------------------------\n\nMap.addLayer(\nDATA,\nVIZ,\nLAYER_NAME,\nfalse,\n1\n)\n\n// -------------------------------------------------------------\n</code></pre></p>"},{"location":"methods/map-layers/#casing-and-fill-viz-for-vector","title":"casing and fill viz for vector","text":"<p><pre><code>// -------------------------------------------------------------\n//  CASING AND FILL VIZ FOR VECTOR DATA\n\n//  This allows you to control display of both casing and fill.\n//  OUTPUT is a single-band image. \n\n//  STEP 1: DEFINE VIZ PARAMETERS\n\n//  Replace VIZ with custom name.\n//  Casing color --&gt; Adjust HTML color name or hex code.\n//  Casing size --&gt; Adjust WEIGHT.\n//  Fill color --&gt; Adjust HTML hex code; last two characters control opacity. \n\n//  STEP 2: STYLE VECTOR WITH VIZ PARAMETERS\n\n//  INPUT is vector data to display.\n//  VIZ is style parameters.\n//  OUTPUT is image data with styled casing and fill.\n\n//  STEP 3: ADD STYLED DATA TO MAP.\n\n//  OUTPUT is from step 2. \n//  Viz parameter slot must be {} placeholder.\n//  Adjust 'LAYER NAME'. \n//  Adjust boolean show argument.   \n\n//  RESOURCES: \n\n//  https://htmlcolorcodes.com/color-names/\n//  https://gist.github.com/lopspower/03fb1cc0ac9f32ef38f4\n//  \n</code></pre> <pre><code>// -------------------------------------------------------------\n\nvar VIZ = {\ncolor: '#DA70D6',\nwidth: 2, fillColor: '#DA70D600'\n}\n;\n\nvar OUTPUT = INPUT.style(VIZ);\n\nMap.addLayer(OUTPUT, {}, \"LAYER NAME\", false);\n\n// -------------------------------------------------------------\n</code></pre></p>"},{"location":"methods/naip/","title":"naip images","text":""},{"location":"methods/naip/#tag-naip-collection-with-date-and-number-of-bands","title":"tag NAIP collection with date and number of bands","text":"<pre><code>// -------------------------------------------------------------\n//  Tag filtered collection with date and number of bands. \n\n//  Collection must be a NAIP image collection.\n// -------------------------------------------------------------\n</code></pre> <pre><code>output = t.tagDateAndBands(collection)\n;\n\n// -------------------------------------------------------------\n</code></pre> <p>You can access the underlying code for this function in the tasks module. </p>"},{"location":"methods/naip/#make-mosaic-image-from-image-collection","title":"make mosaic image from image collection","text":"<pre><code>// -------------------------------------------------------------\n//  Make mosaic image from image collection\n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = t.makeMosaic(collection, year, region);\n\n// -------------------------------------------------------------\n</code></pre> <p>You can access the underlying code for this function in the tasks module. </p>"},{"location":"methods/terrain/","title":"terrain operations","text":""},{"location":"methods/terrain/#make-hillshade-from-collection","title":"make hillshade from collection","text":"<pre><code>// -------------------------------------------------------------\n//  MAKE HILLSHADE FROM COLLECTION\n//  \n//  DEM_IC is a collection of DEM images.\n//  AZIMUTH is the position of the sun on the horizon; should be 315 +/- 45.\n//  ZENITH is the vertical position of the sun (above the horizon).\n//  Z-factor is exaggeration factor; &gt;1 increases contrast.\n// -------------------------------------------------------------\n</code></pre> <pre><code>var z = 1.2;            // Adjust based on terrain characteristics. \n\n// Make hillshades from collection. \n\nvar hs = dem_ic\n.map(t.hsCollection(320, 35, z))             // Adjust for your terrain.\n.mosaic()                                    .rename('hillshade')\n;\n</code></pre> <p>You can access the underlying code for this function in the tasks module. </p>"},{"location":"methods/terrain/#calculate-slope-as-percent-from-collection","title":"calculate slope as percent from collection","text":"<pre><code>// -------------------------------------------------------------\n//  CALCULATE SLOPE AS PERCENT FROM COLLECTION  \n//  \n//  INPUT is a collection of DEM images.  \n//  OUTPUT is a an image where each pixel reports slope as percent.\n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = input.map(t.percentSlopeCollection)\n.mosaic()\n;\n</code></pre> <p>You can access the underlying code for this function in the tasks module. </p>"},{"location":"methods/terrain/#classify-slope-with-usda-criteria","title":"classify slope with usda criteria","text":"<pre><code>// -------------------------------------------------------------\n//  CLASSIFY SLOPE WITH USDA CRITERIA  \n//  \n//  INPUT is a slope image in units PERCENT.  \n//  OUTPUT is a dictionary with four keys:\n//    i: nominal image based on USDA slope classes,\n//    layer_name: 'USDA slope classification'  \n//    class_names: names of each class,\n//    viz: viz parameters for the image.  \n// -------------------------------------------------------------\n</code></pre> <pre><code>var output = t.classSlopeUSDA(input);\n</code></pre> <p>You can access the underlying code for this function in the tasks module. </p>"},{"location":"methods/zonal-operations/","title":"zonal operations","text":""},{"location":"methods/zonal-operations/#zonal-summary-of-dough-within-cutters","title":"zonal summary of dough within cutters","text":"<pre><code>// -------------------------------------------------------------\n//  ZONAL SUMMARY OF DOUGH WITHIN CUTTERS.\n\n//  Adjust CRS for your study region.  \n//  DOUGH must be an image with values to summarize. \n//  CUTTERS must be a feature collection.  \n//  Adjust REDUCER for desired summary statistic.\n//  Adjust SCALE to tune processing time vs acceptable accuracy.  \n//  ZS will be a feature collection.\n//  The name of ZS property will reflect the REDUCER.   \n//  In below example, ZS property is 'sum'.  \n// -------------------------------------------------------------\n</code></pre> <pre><code>var crs = \"EPSG:32145\";             // Good for Vermont.\n\nvar zs = dough\n.reduceRegions(\n{\ncollection: cutters, reducer: ee.Reducer.sum(), scale: 3, crs: crs\n}\n)\n;\n\n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/area-problems/","title":"area problems","text":"<p>Please work through this problem set and then give your best shot at the challenge problem.  </p> <p>Please note that for the first four problems, I provide links to workflows and answers that you may use to help guide and check your work. Your task is to write scripts that generate the answers.     </p> <p>To get started, create a folder in your working repository named area.</p>"},{"location":"problems/area-problems/#how-much","title":"How much?","text":"<p>We can start with a basic question: how much area does a feature collection contain?  </p> <p>For example:  </p> <p>How much land does Middlebury College own in Vermont? </p> <p>We can answer this question with either a vector or raster solution.  </p>"},{"location":"problems/area-problems/#vector-approach","title":"Vector approach","text":"<p>Start a new script in your area folder called 01_basic_vector.js.</p> <p>Insert a code snippet like this as a header:   </p> <pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  BASIC VECTOR SOLUTION\n//  Example: How much land does Middlebury College own?\n\n//  Last modified: insert date\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre> <p>Now write a script that computes the total acreage of parcels owned by the college (from data.cadastre.college).  </p> <p>If you would like a template and answers to help you check your work, then here is a workflow.  </p>"},{"location":"problems/area-problems/#raster-approach","title":"Raster approach","text":"<p>In earth engine, a raster solution employs a ZONAL operation.     </p> <p>Start a new script in your area folder called 02_basic_raster.js.</p> <p>Insert a code snippet like this as a header:    </p> <pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  BASIC RASTER SOLUTION\n//  Example: How much land does Middlebury College own?\n\n//  Last modified: insert date\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre> <p>Now write a script that computes the total acreage of parcels owned by the college (from data.cadastre.college) using a ZONAL operation with a raster input.  </p> <p>If you would like a template and answers to help you check your work, then here is workflow.  </p>"},{"location":"problems/area-problems/#reflection","title":"Reflection","text":"<p>Please think about the following:  </p> <ol> <li>Compare your answers from the two solutions: how close are they?  </li> <li>How sensitive is the raster solution to your choice of scale?  </li> </ol>"},{"location":"problems/area-problems/#theme-within-regions","title":"Theme within regions","text":"<p>The first two solutions gave us how much area within each and all regions, where a feature collection represents a set of regions.   </p> <p>The next problem looks to measure the amount of a theme within a set of regions.  </p> <p>The basic question is:  </p> <p>How much area of a particular theme occurs within a region or set of regions? </p> <p>For example:</p> <p>How many acres of rare or significant natural communities does the College own? </p> <p>This type of problem can be easily solved with a raster overlay operation that builds on the basic solution solved previously.     </p>"},{"location":"problems/area-problems/#raster-solution","title":"Raster solution","text":"<p>Start a new script in your area folder called 03_theme_in_regions.js.</p> <p>Insert a code snippet like this as a header:    </p> <pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  THEME IN REGIONS  \n//  Example: How many acres of rare or significant natural \n//  communities does Middlebury College own?  \n\n//  Last modified: insert date\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre> <p>Now write a script that computes the total acreage of rare and significant natural communities (data.rarity.vt.nc) that occur within college-owned parcels (data.cadastre.college) that builds on the previous raster-based solution.  </p> <p>If you would like a template and answers to help you check your work, then here is a workflow.  </p>"},{"location":"problems/area-problems/#theme-within-sites-across-regions","title":"Theme within sites across regions","text":"<p>In the previous problems, we allowed the extent of a feature collection to define the extent of our analysis.  </p> <p>The next problem looks to make comparisons of THEMES in SITES across COMPARISON REGIONS.  </p> <p>Perhaps you can suggest better terms to describe the general case for this after you work through the problem, but here is the concrete example:  </p> <p>How many acres of rare or significant natural communities does the College own in each town? </p> <p>In this example, the THEME is rare or significant natural communities, the SITES are college parcels, and the REGIONS are towns in Vermont.  </p> <p>This type of problem can again be easily solved with a raster overlay operation that builds on the previous solution.  </p>"},{"location":"problems/area-problems/#raster-solution_1","title":"Raster solution","text":"<p>Start a new script in your area folder called 04_theme_in_sites_across_regions.js.</p> <p>Insert a code snippet like this as a header:    </p> <pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  THEME IN SITES ACROSS REGIONS  \n//  Example: How many acres of rare or significant natural \n//  communities does Middlebury College own in each town?  \n\n//  Last modified: insert date\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre> <p>Now build on the previous solutions and write a script that computes the total acreage of rare and significant natural communities (data.rarity.vt.nc) that occur within college-owned parcels (data.cadastre.college) in each town that contains college-owned parcels.  </p> <p>If you would like a template and answers to help you check your work, then here is a workflow.  </p>"},{"location":"problems/area-problems/#reflection_1","title":"Reflection","text":"<p>Please think about these three questions:  </p> <ol> <li>How many cutters do we have in this solution?  </li> <li>How does the total area reported in this solution compare to previous?</li> <li>Why might they differ?  </li> </ol>"},{"location":"problems/area-problems/#map","title":"Map","text":"<p>You can adapt this snippet to map the layers.</p> <pre><code>// ------------------------------------------------------------------------------------------------------\n//  MAP\n// ------------------------------------------------------------------------------------------------------\n\nvar palettes = {\ncutters: '#78b3e0',\ntheme: '#7A995C'\n}\n;\n\nMap.centerObject(regions, 10);\nMap.setOptions('hybrid');\n\nvar regions_style = {color: '#ffffff', width: 6, fillColor: 'ffffff00'};\n\nMap.addLayer(regions.style(regions_style), {}, \"Regions\");\nMap.addLayer(sites, {color: palettes.cutters}, \"Sites\", true, 0.75);\nMap.addLayer(theme, {color: palettes.theme}, \"Theme\");\n</code></pre>"},{"location":"problems/area-problems/#chart","title":"Chart","text":"<p>You can adapt this script to chart your results.  </p> <pre><code>// ------------------------------------------------------------------------------------------------------\n//  Charts  \n// ------------------------------------------------------------------------------------------------------\n\n// Make a bar chart for the total acreage per town.\n\nvar chart = ui.Chart.feature.byFeature(\n{\nfeatures: zs.sort(\"sum\", false), xProperty: 'TOWNNAME', yProperties: ['sum']\n})\n.setSeriesNames(['Rare Nat Communities'])\n.setChartType('ColumnChart')\n.setOptions({\ntitle: 'Town Comparison',\nhAxis: {title: 'Town'},\nvAxis: {title: 'Acres'},\ncolors: [palettes.theme]\n});\n\nprint(chart);\n</code></pre>"},{"location":"problems/area-problems/#challenge-problem","title":"Challenge Problem","text":"<p>Your challenge problem is to report the amount of a THEME within SITES across REGIONS and the amount of the THEME across REGIONS in a single chart like this:  </p> <p></p> <p>Start a new script in your area folder called 05_theme_in_sites_across_regions_challenge.js.</p> <p>Insert a code snippet like this as a header:    </p> <pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  THEME IN SITES ACROSS REGIONS CHALLENGE\n\n//  Compare total area of THEME to total area of SUBJECT. \n\n//  Last modified: insert date\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre> <p>You should be able to recycle the majority of your last solution. You just need to do a little surgery. </p> <p>Click here if you would like some clues.  </p> <p>No pressure. Please let me know if you have questions.  </p>"},{"location":"problems/nominal-problems/","title":"nominal problems","text":""},{"location":"problems/nominal-problems/#introduction","title":"Introduction","text":"<p>Nominal problems concern transforming (making purposeful changes) to names at locations. Often, the names describe kinds of things (categories, classes, types). You can think of nominal operations as those that alter the lexicon of the map, or the number of names that are available to describe spatial variation in a layer.   </p> <p> Operation Lexicon to describe spatial variation Generalize Use fewer names. Specify Use more names. <p></p> <p>In practice, you often apply nominal operations surgically, altering a subset of names in a subregion of the layer.     </p>"},{"location":"problems/nominal-problems/#illustration","title":"Illustration","text":"<p>To illustrate, we will use Vermont\u2019s  Statewide High-Resolution Land Cover Dataset from the Awesome Community Datasets repo.  </p> <p>Our goal is to specify agriculture from other grasslands in specific zones of the layer. </p>"},{"location":"problems/nominal-problems/#implementation","title":"Implementation","text":"<p>Start a new script in our repo called nominal.js.  </p> <p>Insert a header, then load the data and task modules.   </p> <pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Nominal problem:\n//  specify different kinds of grasslands.\n\n//  Last modified: insert date\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar data = require('users/jhowarth/public:modules/data.js');       print('DATA', data);\n\nvar t = require('users/jhowarth/public:modules/tasks.js');\n</code></pre> <p>Now write a script that meets the following conditions:  </p> <ol> <li>Defines agricultural lands with data from data.lc.ag.</li> <li>Records a new class for agriculture at any grass/shrub or bare ground location in the base layer (data.lc.base).</li> <li>Does not alter any other class (tree canopy, water, road, etc).</li> </ol> <p>If you would like a template and answers to help you check your work, then here is a workflow.  </p>"},{"location":"problems/proximity-problems/","title":"proximity problems","text":""},{"location":"problems/proximity-problems/#introduction","title":"Introduction","text":"<p>Proximity problems deal with relative distance, or how far a location is from another location. </p> <p>A classic proximity problem involves classifying a threshold distance from a feature or collection of features. Often this zone of influence is called a buffer.   </p>"},{"location":"problems/proximity-problems/#illustration","title":"Illustration","text":"<p>To illustrate, we will use an ancillary dataset from Vermont\u2019s  Statewide High-Resolution Land Cover Dataset hosted on my data repo. </p> <p>Your goal is to use the \u201c3D Building Roofprint\u2019 collection to specify a zone that is 100 feet to the nearest human structure.   </p>"},{"location":"problems/proximity-problems/#implementation","title":"Implementation","text":"<p>Start a new script called proximity_problem.js.</p> <p>Insert a header, then load the data and task modules.   </p> <pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  PROXIMITY PROBLEM\n//  Specify a zone based on distance to nearest human structure. \n\n//  Last modified: insert date\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar data = require('users/jhowarth/public:modules/data.js');       print('DATA', data);\n\nvar t = require('users/jhowarth/public:modules/tasks.js');\n</code></pre> <p>Now write a script that produces a binary raster layer of all locations within 100 feet of a human structure (from data.lc.buildings).  </p> <p>If you would like a template and answers to help you check your work, then here is a workflow.</p>"},{"location":"problems/terrain-problems/","title":"terrain problems","text":""},{"location":"problems/terrain-problems/#introduction","title":"Introduction","text":"<p>Terrain problems concern how to represent the earth\u2019s surface and the age-old problem of how to represent a third spatial dimension on a flat visual plane. </p> <p>Two classic terrain problems involve:  </p> <ol> <li> <p>creating the illusion of a third dimension through shading from an illumination source, often called shaded relief;</p> </li> <li> <p>classifying the degree of change in a surface as illustrated by a slope map.    </p> </li> </ol>"},{"location":"problems/terrain-problems/#shaded-relief","title":"SHADED RELIEF","text":"<p>Use the USGS 3DEP 1m National Map hosted by Google to make a hyposmetric shaded relief map (as shown below).</p> <p>Start a new script called wk04_01_shaded_relief.js.</p> <p>Insert a header, then load the data and task modules.   </p> <pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  SHADED RELIEF  \n\n//  Make a blended hypsometric shaded relief.  \n\n//  Last modified: insert date\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar data = require('users/jhowarth/public:modules/data.js');       print('DATA', data);\n\nvar t = require('users/jhowarth/public:modules/tasks.js');\n</code></pre> <p>Now write a script that produces the layers shown in the app above.    </p> <p>If you would like a template, then here is a workflow.</p>"},{"location":"problems/terrain-problems/#classified-slope-map","title":"CLASSIFIED SLOPE MAP","text":"<p>Use the USGS 3DEP 1m National Map hosted by Google to make a slope map with classes defined by the USDA.  </p> <p>Start a new script called wk04_02_slope_class.js.</p> <p>Insert a header, then load the data and task modules.   </p> <pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  CLASSIFIED SLOPE MAP\n\n//  Make a slope map with classes defined by USDA.  \n\n//  Last modified: insert date\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar data = require('users/jhowarth/public:modules/data.js');       print('DATA', data);\n\nvar t = require('users/jhowarth/public:modules/tasks.js');\n</code></pre> <p>Now write a script that produces the layers shown in the app above.  </p> <p>If you would like a template, then here is a workflow.</p>"},{"location":"q-methods/add-google-xyz/","title":"google base maps","text":""},{"location":"q-methods/add-google-xyz/#overview","title":"Overview","text":"<p>The video below shows you how to add a Google base map to QGIS. You should only need to connect the Google service to a Q project once. After this, all of your Q projects should remember the connection.   </p>"},{"location":"q-methods/add-google-xyz/#hybrid","title":"Hybrid","text":"<pre><code>https://mt1.google.com/vt/lyrs=y&amp;x={x}&amp;y={y}&amp;z={z}\n</code></pre>"},{"location":"q-methods/add-google-xyz/#satellite","title":"Satellite","text":"<pre><code>http://www.google.cn/maps/vt?lyrs=s@189&amp;gl=cn&amp;x={x}&amp;y={y}&amp;z={z}\n</code></pre>"},{"location":"q-methods/add-google-xyz/#terrain","title":"Terrain","text":"<pre><code>https://mt1.google.com/vt/lyrs=p&amp;x={x}&amp;y={y}&amp;z={z}\n</code></pre>"},{"location":"q-methods/add-google-xyz/#map","title":"Map","text":"<pre><code>https://mt1.google.com/vt/lyrs=r&amp;x={x}&amp;y={y}&amp;z={z}\n</code></pre>"},{"location":"q-methods/add-google-xyz/#roads","title":"Roads","text":"<pre><code>https://mt1.google.com/vt/lyrs=h&amp;x={x}&amp;y={y}&amp;z={z}\n</code></pre>"},{"location":"q-methods/custom-palettes/","title":"custom palettes in qgis","text":""},{"location":"q-methods/custom-palettes/#introduction","title":"Introduction","text":"<p>You can create custom palettes in qgis manually with a lot of clicking, or you can upload a custom palette file. I will put palettes that we use in Earth Engine in this repository.  </p>"},{"location":"q-methods/custom-palettes/#walk-through","title":"Walk through","text":"<p>The video below shows you how to upload a .gpl file to define a custom palette in QGIS. It demonstrates the method with the land cover layer that you can export through this example. </p>"},{"location":"q-methods/vermont-lidar/","title":"vermont lidar","text":""},{"location":"q-methods/vermont-lidar/#introduction","title":"Introduction","text":"<p>You can access lidar raster products from VCGI one tile at a time through the Vermont Lidar Finder. This will require a lot of clicks and post-processing (mosaic tiles).  </p> <p>Recently, the folks at VCGI have developed a seamless cloud optimized geotiff (COG) product that you can access through QGIS. These datasets support a simple two-step workflow for accessing high resolution (70 cm) datasets for custom subregions within Vermont:   </p> <ol> <li>Add a COG to QGIS with a cloud protocol.</li> <li>Extract data from a subregion.  </li> </ol> <p>On 3/30/2024, I tested this workflow with QGIS 3.32.2 Lima. If you are not able to add the COG with the cloud protocol, you may need to update your QGIS to the latest stable version.</p>"},{"location":"q-methods/vermont-lidar/#cloud-protocols","title":"Cloud protocols","text":"<p>As of 3/30/2024, VCGI provides a hydro-flattened DEM and a DSM (from first returns) in the COG format.  </p>"},{"location":"q-methods/vermont-lidar/#demhf","title":"DEMHF","text":"<pre><code>https://s3.us-east-2.amazonaws.com/vtopendata-prd/Elevation/STATEWIDE_2013-2017_70cm_DEMHF.tif\n</code></pre>"},{"location":"q-methods/vermont-lidar/#dsm","title":"DSM","text":"<pre><code>https://s3.us-east-2.amazonaws.com/vtopendata-prd/Elevation/STATEWIDE_2013-2017_70cm_DSM.tif\n</code></pre>"},{"location":"q-methods/vermont-lidar/#add-cog-to-qgis","title":"Add COG to QGIS","text":"<p>The first step involves adding the COG to QGIS with one of the cloud protocols defined above. </p>"},{"location":"q-methods/vermont-lidar/#extract-study-region","title":"Extract study region","text":"<p>The second step involves extracting values from a subregion of the COG with a vector layer.  </p> <p>GG0352 students: Please note that I placed copies of the two extracted datasets in the shared DATA/elevation folder for you to use in the whitebox challenge problems if you have trouble extracting the lidar datasets. </p>"},{"location":"wb-methods/hello-whitebox/","title":"hello whitebox","text":""},{"location":"wb-methods/hello-whitebox/#directory-structure","title":"directory structure","text":"<p>You will need to set up a workspace as shown below.    </p> <ol> <li>Make a project folder (in example I called this GEOG0352).</li> <li>Place WBT folder in the project folder.</li> <li>Create hello-whitebox.py file in the project folder (above the WBT).  </li> </ol> <p></p>"},{"location":"wb-methods/hello-whitebox/#write-a-header","title":"write a header","text":"<pre><code># ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n#   Hello Whitebox\n#   \n#   To test my whitebox configuration.\n#   Date\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  \n</code></pre>"},{"location":"wb-methods/hello-whitebox/#load-modules","title":"load modules","text":"<pre><code># import tools from WBT module\n\nfrom WBT.whitebox_tools import WhiteboxTools\n\n# declare a name for the tools\n\nwbt = WhiteboxTools()\n</code></pre>"},{"location":"wb-methods/hello-whitebox/#set-up-your-working-directory","title":"set up your working directory","text":"<pre><code># Set your working directory - where you will read and write files. \n# NOTE: You will need to customize the path name below. \n\nwork =  \"/Users/jhowarth/Library/CloudStorage/GoogleDrive-jhowarth@middlebury.edu/Shared drives/GEOG0352-S24/\"\n\nwbt.work_dir = work\n</code></pre>"},{"location":"wb-methods/hello-whitebox/#declare-names-for-output-directory-and-starter-data","title":"declare names for output directory and starter data","text":"<pre><code># Declare a directory for our outputs  \n\nout = work + \"jhowarth/outputs/\"\n\n# Declare a name for our test data\n\ndsm = work + \"DATA/_test_dsm.tif\"\n</code></pre>"},{"location":"wb-methods/hello-whitebox/#call-a-whitebox-operation","title":"call a whitebox operation","text":"<pre><code># Call the slope tool and define parameters\n\nwbt.slope(\n    dem = dsm,\n    output = out + \"_test_slope.tif\",\n    zfactor=None,\n    units=\"degrees\"\n)\n</code></pre>"},{"location":"wb-methods/hello-whitebox/#visualize-output-with-qgis","title":"visualize output with QGIS","text":"<ol> <li>Open QGIS  </li> <li>Save new project as \u2018wb_viewer\u2019 in your cloud project directory and at the same level as your outputs folder. </li> <li>Add data to QGIS project from outputs folder. </li> </ol>"},{"location":"wb-methods/hello-whitebox/#use-whitebox-manual-to-call-other-operations","title":"use whitebox manual to call other operations","text":"<p>Whitebox Tools manual</p> <pre><code># Threshold the slope output: less than or equal to 10 degrees.  \n\n# BASIC SYNTAX\n# after argument: =\n# before file names: out +  \n# include filename extension: .tif \n# delete callback\n</code></pre>"},{"location":"wb-methods/hello-whitebox/#challenge","title":"challenge","text":"<pre><code># Calculate surface height (not elevation)\n</code></pre>"},{"location":"wb-methods/mama-raster/","title":"mama raster","text":""},{"location":"wb-methods/mama-raster/#overview","title":"Overview","text":"<p>In most (if not all) cases, Whitebox will panic if you try to compare two layers that do not align perfectly. As a result, for any local or zonal operation that requires two inputs, you will need to make sure that each input image has the same pixel resolution and the same extent (number of rows and columns). </p> <p>For this problem, I generally assign one image to serve as a mama raster, or a raster with a cell size and extent that will be inherited by all other rasters in the module. </p>"},{"location":"wb-methods/mama-raster/#choosing-a-mama","title":"Choosing a mama","text":"<p>In general, your choice of which image to assign as mama should usually prioritize down-sampling (reducing resolution) over up-sampling (increasing resolution).</p> Cell Size Extent Strategy Same Differ Either raster could serve as mama. Differ Same Lower resolution should be mama. Differ Differ Lower resolution should be mama. <p>In some cases, the two rasters will have the same resolution, but may have minor or major misalignments in the extent. Either raster could serve as the mama. </p> <p>In other cases, the two rasters will have different resolutions. It is often better to down-sample and assign the lower resolution raster as mama.  </p>"},{"location":"wb-methods/mama-raster/#operation","title":"Operation","text":"<p>In Whitebox, the Resample tool can be used to change the resolution and extent of an image to match a mama image. The key is to use the base parameter rather than the scale parameter. This will assign both the cell size and the extent of the base raster to the output raster.  </p> <p>Please note that the method parameter is also very important. It should be \u201cnn\u201d for discrete data (nominal, ordinal, interval) and either \u201cbilinear\u201d or \u201ccc\u201d for continuous data (ratio).    </p> <pre><code># Align with mama.    \n\nwbt.resample(\n    inputs = input1, \n    output = output1, \n    cell_size=None, \n    base=mama, \n    method=\"nn\",    # \"nn\" for discrete; \"bilinear\" or \"cc\" for continuous \n    # callback=default_callback\n)\n</code></pre>"},{"location":"workflows/area-workflows/","title":"area workflows","text":"<p>This page outlines workflows to solve the area problems with earth engine methods defined on the methods pages.  </p>"},{"location":"workflows/area-workflows/#vector-approach","title":"Vector approach","text":"<p>Here is a workflow to solve the vector-based approach to the area problem.</p>"},{"location":"workflows/area-workflows/#load-modules","title":"Load modules.","text":"<ol> <li>Load the data module. </li> <li>Load the tasks module.</li> </ol>"},{"location":"workflows/area-workflows/#define-a-subject","title":"Define a SUBJECT.","text":"<ol> <li>Load feature collection from address \u2192 data.cadastre.college.fc_address </li> <li>Print the number of objects in the collection. \u2192 Answer A below  </li> </ol>"},{"location":"workflows/area-workflows/#calculate-area-of-each-subject-feature","title":"Calculate area of each SUBJECT feature.","text":"<ol> <li>Area of features (acres) in FC.</li> </ol>"},{"location":"workflows/area-workflows/#print-results","title":"Print results.","text":"<ol> <li>Print size of collection. \u2192 Answer B below</li> <li>Sum the values in a table column. \u2192 Answer C below</li> </ol> Check your answers for vector solution.  (A) Number of parcels owned by the college: 286  (B) Number of objects in SUBJECT collection: 286   (C) Total acres of college-owned parcels: 7009"},{"location":"workflows/area-workflows/#raster-approach","title":"Raster approach","text":"<p>Work through the steps below to solve the raster-based approach to the area problem.  </p>"},{"location":"workflows/area-workflows/#load-modules_1","title":"Load modules.","text":"<ol> <li>Load the data module. </li> <li>Load the tasks module. </li> </ol>"},{"location":"workflows/area-workflows/#define-cutters","title":"Define CUTTERS.","text":"<ol> <li>Load feature collection from address \u2192 data.cadastre.college.fc_address </li> <li>Print size collection. \u2192 Answer A below  </li> </ol>"},{"location":"workflows/area-workflows/#define-the-dough","title":"Define the DOUGH.","text":"<ol> <li>Make pixel area image. </li> </ol>"},{"location":"workflows/area-workflows/#compute-zonal-summary-zs","title":"Compute Zonal Summary (zs).","text":"<ol> <li>Zonal summary of dough within cutters. </li> </ol>"},{"location":"workflows/area-workflows/#print-results_1","title":"Print results.","text":"<ol> <li>Print size of collection. \u2192 Answer B below</li> <li>Sum the values in a table column (FC property). \u2192 Answer C below</li> </ol> Check your answers for raster-based solution.  (A) Number of parcels owned by the college: 286  (B) Number of objects in zs collection: 286   (C) Total acres of college-owned parcels: 7009"},{"location":"workflows/area-workflows/#theme-within-regions","title":"Theme within regions","text":"<p>Work through the steps below to solve the theme within regions area problem.  </p>"},{"location":"workflows/area-workflows/#load-modules_2","title":"Load modules.","text":"<ol> <li>Load the data module. </li> <li>Load the tasks module. </li> </ol>"},{"location":"workflows/area-workflows/#define-cutters_1","title":"Define CUTTERS.","text":"<ol> <li>Load feature collection from address \u2192 data.cadastre.college.fc_address </li> <li>Print size collection. \u2192 Answer A below  </li> </ol>"},{"location":"workflows/area-workflows/#define-binary-theme","title":"Define binary THEME.","text":"<ol> <li>Load feature collection from address. \u2192 data.rarity.vt.nc.fc_address </li> <li>Inspect the properties of the feature collection.<ol> <li>Print first feature in FC.</li> <li>Print unique values in FC.<ol> <li>Explore \u2018S_RANK\u2019.</li> <li>Explore \u2018S_NAME\u2019.  </li> </ol> </li> <li>Convert FC to binary image. \u2192 THEME as input</li> </ol> </li> </ol>"},{"location":"workflows/area-workflows/#define-the-dough_1","title":"Define the DOUGH.","text":"<ol> <li>Make pixel area image. </li> <li>Erase values at locations with binary. \u2192 pixel area and theme binary </li> </ol>"},{"location":"workflows/area-workflows/#compute-zonal-summary-zs_1","title":"Compute Zonal Summary (zs).","text":"<ol> <li>Zonal summary of dough within cutters. </li> </ol>"},{"location":"workflows/area-workflows/#print-results_2","title":"Print results.","text":"<ol> <li>Print size of collection. \u2192 Answer B below</li> <li>Sum the values in a table column. \u2192 Answer C below</li> </ol> Check your answers for THEME IN REGIONS raster solution.  (A) Number of parcels owned by the college: 286  (B) Number of objects in zs collection: 286   (C) Total acres of rare natural communities on college-owned parcels: 1284"},{"location":"workflows/area-workflows/#theme-within-sites-across-regions","title":"Theme within sites across regions","text":"<p>Work through the steps below to solve the theme within sites across regions area problem.</p>"},{"location":"workflows/area-workflows/#load-modules_3","title":"Load modules.","text":"<ol> <li>Load the data module. </li> <li>Load the tasks module. </li> </ol>"},{"location":"workflows/area-workflows/#define-sites","title":"Define SITES.","text":"<ol> <li>Load feature collection from address \u2192 data.cadastre.college.fc_address </li> <li>Print size of collection. \u2192 Answer A below     </li> <li>Convert FC to binary image. \u2192 Use SITES as input.</li> </ol>"},{"location":"workflows/area-workflows/#define-regions","title":"Define REGIONS.","text":"<ol> <li>Load feature collection from address \u2192 data.gov.town.fc_address    </li> <li>Filter collection by bounds. \u2192 towns that intersect college parcels</li> <li>Print the number of objects in the collection. \u2192 Answer ABbelow </li> </ol>"},{"location":"workflows/area-workflows/#define-theme","title":"Define THEME.","text":"<ol> <li>Load feature collection from address. \u2192 data.rarity.vt.nc.fc_address </li> <li>Inspect the properties of the feature collection.<ol> <li>Print first feature in FC.</li> <li>Print unique values in FC.<ol> <li>Explore \u2018S_RANK\u2019.</li> <li>Explore \u2018S_NAME\u2019.  </li> </ol> </li> </ol> </li> <li>Convert FC to binary image. \u2192 THEME as input  </li> </ol>"},{"location":"workflows/area-workflows/#define-the-dough_2","title":"Define the DOUGH.","text":"<ol> <li>Make pixel area image. </li> <li>Erase values at locations with binary. \u2192 pixel area and theme binary and sites binary</li> </ol>"},{"location":"workflows/area-workflows/#compute-zonal-summary-zs_2","title":"Compute Zonal Summary (zs).","text":"<ol> <li>Zonal summary of dough within cutters. \u2192 REGIONS as cutters!</li> </ol>"},{"location":"workflows/area-workflows/#print-results_3","title":"Print results.","text":"<ol> <li>Print size of collection. \u2192 Answer C below</li> <li>Sum the values in a table column. \u2192 Answer D below  </li> </ol> Check your answers for THEME IN SITES ACROSS REGIONS raster solution.  (A) Number of parcels owned by the college: 286  (B) Number of towns that intersect college lands: 9   (C) Number of REGIONS in the zs output: 9   (D) Total acres of rare natural communities on college-owned parcels: 1301"},{"location":"workflows/area-workflows/#challenge-problem","title":"Challenge problem","text":"<p>Here are some clues to solve the area challenge problem.  </p> <ul> <li>Your dough will need two bands.<ol> <li>One of pixel areas for locations that are THEME and SITE.</li> <li>Another of pixel areas for locations that are THEME.  </li> </ol> </li> </ul> <pre><code>var dough = dough_theme_sites.addBands(dough_theme);\n</code></pre> <ul> <li>You will need to alter some parameters in the Chart to reflect that you are charting two series:  <ol> <li>yProperties  </li> <li>.setSeriesNames  </li> <li>colors   </li> </ol> </li> </ul>"},{"location":"workflows/nominal-workflows/","title":"nominal workflows","text":"<p>It is good practice to self check your work by printing new outputs to console and adding new outputs as layers to the map. Try to get into the habit of pausing your progress after each step so that you can check if your output looks right before continuing.     </p>"},{"location":"workflows/nominal-workflows/#define-study-site","title":"Define study site","text":"<pre><code>// -------------------------------------------------------------\n//  DEFINE STUDY SITE. \n// -------------------------------------------------------------\n</code></pre> <ol> <li>Load FC from address. \u2192 data.cadastre.college </li> </ol>"},{"location":"workflows/nominal-workflows/#make-binary","title":"Make binary","text":"<pre><code>// -------------------------------------------------------------\n//  MAKE BINARY OF AG. \n// -------------------------------------------------------------\n</code></pre> <ol> <li>Load FC from address. \u2192 data.lc.ag</li> <li>Convert ag FC to binary image. </li> </ol>"},{"location":"workflows/nominal-workflows/#generalize-layer","title":"Generalize layer","text":"<pre><code>// -------------------------------------------------------------\n//  GENERALIZE LC LAYER.\n// -------------------------------------------------------------\n</code></pre> <ol> <li>Reclassify a nominal image. </li> </ol>"},{"location":"workflows/nominal-workflows/#isolate-subregion","title":"Isolate subregion","text":"<pre><code>// -------------------------------------------------------------\n//  ISOLATE LC SUBREGION.\n// -------------------------------------------------------------\n</code></pre> <ol> <li>Intersect two binaries. </li> </ol>"},{"location":"workflows/nominal-workflows/#specify-new-lc-names","title":"Specify new LC names","text":"<pre><code>// -------------------------------------------------------------\n//  SPECIFY NEW LC NAMES.\n// -------------------------------------------------------------\n</code></pre> <ol> <li>Multiply image by constant </li> <li>Maximum at locations. </li> </ol>"},{"location":"workflows/proximity-workflows/","title":"proximity workflows","text":"<p>It is good practice to self check your work by printing new outputs to the console panel and adding new outputs as layers to the map panel. The workflow below does not prompt you to do this; you should be in the habit of doing this automatically. Please reference the inspect properties and map layer methods as needed.</p>"},{"location":"workflows/proximity-workflows/#define-study-sites","title":"Define study sites","text":"<pre><code>// -------------------------------------------------------------\n//  1. DEFINE STUDY SITE. \n// -------------------------------------------------------------\n</code></pre> <ol> <li>Load feature collection \u2192 data.cadastre.college </li> <li>Set up your map to center on study site and show hybrid base layer. </li> </ol>"},{"location":"workflows/proximity-workflows/#map-features-of-interest","title":"Map features of interest","text":"<pre><code>// -------------------------------------------------------------\n//  2. LOAD BUILDING ROOFPRINTS ON COLLEGE LANDS. \n// -------------------------------------------------------------\n</code></pre> <ol> <li>Load feature collection \u2192 data.lc.buildings </li> <li>Filter collection by region \u2192 buildings on college parcels.</li> </ol>"},{"location":"workflows/proximity-workflows/#map-zones-of-interest","title":"Map zones of interest","text":"<pre><code>// -------------------------------------------------------------\n//  3. MAP 100 FT ZOI FOR EACH BUILDING ON COLLEGE LANDS.  \n// -------------------------------------------------------------\n</code></pre> <ol> <li>Buffer each feature in a collection. </li> </ol>"},{"location":"workflows/proximity-workflows/#map-binary-proximity-zone","title":"Map binary proximity zone","text":"<pre><code>// -------------------------------------------------------------\n//  4. MAP BINARY PROXIMITY ZONE.  \n// -------------------------------------------------------------\n</code></pre> <ol> <li>Convert fc to binary image.</li> </ol>"},{"location":"workflows/proximity-workflows/#challenge-problems","title":"Challenge Problems","text":"<ol> <li>Could you solve step 3 with a raster solution (where you do not use the f.buffer method to map proximity)?</li> <li>Could you solve step 4 with a vector solution (what you do not convert fc to binary image)?  </li> </ol>"},{"location":"workflows/proximity-workflows/#reflections","title":"Reflections","text":"<ol> <li>What are pros and cons of vector solution to define proximity zones compared to raster solution?    </li> <li>What are pros and cons of raster solution to make binary image versus the vector solution of dissolving features?    </li> </ol>"},{"location":"workflows/terrain-workflows/","title":"terrain workflows","text":"<p>It is good practice to self check your work by printing new outputs to the console panel and adding new outputs as layers to the map panel. The workflow below does not prompt you to do this; you should be in the habit of doing this automatically. Please reference the inspect properties and map layer methods as needed.  </p> <p>In general, you should try to print and/or add a layer to each map in each chunk of the problem. </p>"},{"location":"workflows/terrain-workflows/#shaded-relief","title":"SHADED RELIEF","text":""},{"location":"workflows/terrain-workflows/#define-study-region","title":"Define study region","text":"<pre><code>// -------------------------------------------------------------\n//  DEFINE STUDY REGION\n//\n//  Make two versions of your study region: \n//  1. a feature collection\n//  2. a binary image\n//\n//  Then set up your map:\n//  1. center on study region at zoom 13\n//  2. change base map to hybrid\n// -------------------------------------------------------------\n</code></pre> <ol> <li>Load feature collection from address \u2192 data.gov.town</li> <li>Filter by attribute \u2192 \u2018MIDDLEBURY\u2019</li> <li>Feature collection to binary image </li> </ol>"},{"location":"workflows/terrain-workflows/#load-elevation-data","title":"Load elevation data","text":"<pre><code>// -------------------------------------------------------------\n//  LOAD ELEVATION DATA: 3DEP 1m DEM\n// -------------------------------------------------------------\n</code></pre> <ol> <li>Load image collection from address \u2192 \u2018USGS/3DEP/1m\u2019  </li> <li>Filter by bounds \u2192 study_region  </li> <li>Select image band \u2192 \u2018elevation\u2019</li> </ol>"},{"location":"workflows/terrain-workflows/#convert-image-collection-to-image","title":"Convert image collection to image","text":"<pre><code>// -------------------------------------------------------------\n//  CONVERT IMAGE COLLECTION INTO AN IMAGE\n//\n//  Mosaic dem and mask by study region.\n// -------------------------------------------------------------\n</code></pre> <ol> <li>Mosaic image collection to image </li> <li>Mask values at locations \u2192 study_region_binary  </li> </ol>"},{"location":"workflows/terrain-workflows/#define-viz-for-image","title":"Define viz for image","text":"<pre><code>// -------------------------------------------------------------\n//  DEFINE VIZ FOR DEM \n// ------------------------------------------------------------- \n</code></pre> <ol> <li>Print min and max of image </li> <li>Define viz parameters \u2192 use min and max that were printed to console  </li> </ol>"},{"location":"workflows/terrain-workflows/#make-hillshade-layer","title":"Make hillshade layer","text":"<pre><code>// -------------------------------------------------------------\n//  MAKE HILLSHADE LAYER  \n// ------------------------------------------------------------- \n</code></pre> <ol> <li>Make hillshade from collection </li> <li>Viz with gamma to influence midtones </li> </ol>"},{"location":"workflows/terrain-workflows/#add-shading-from-another-hillshade-with-a-different-azimuth","title":"Add shading from another hillshade with a different azimuth","text":"<pre><code>// ------------------------------------------------------------- \n//  ADD SHADING FROM ANOTHER HILLSHADE WITH A DIFFERENT AZIMUTH \n// ------------------------------------------------------------- \n</code></pre> <ol> <li>Make hillshade from collection </li> <li>Minimum at locations </li> </ol>"},{"location":"workflows/terrain-workflows/#convert-to-feet","title":"Convert to feet","text":"<pre><code>// ------------------------------------------------------------- \n//  CONVERT TO FEET\n// ------------------------------------------------------------- \n</code></pre> <ol> <li>Mask values at locations \u2192 study_region_binary  </li> <li>Multiply image by constant \u2192 3.28084  </li> <li>Print min and max of image </li> </ol>"},{"location":"workflows/terrain-workflows/#classify-hypsography","title":"Classify hypsography","text":"<pre><code>// ------------------------------------------------------------- \n//  CLASSIFY HYPSOGRAPHY\n// ------------------------------------------------------------- \n</code></pre> <ol> <li>Classify image by equal intervals \u2192 100  </li> <li>Print min and max of image </li> </ol> <pre><code>var hypso_palette = ['#bfd3b5', '#cbdabf', '#e2e0c3', '#efdeba', '#edd2a3', '#eaca91', '#e6c084', '#dbad70', '#ce975b', '#c68d51'];\n</code></pre>"},{"location":"workflows/terrain-workflows/#blend-hypsometric-tint-with-shaded-relief","title":"Blend hypsometric tint with shaded relief","text":"<pre><code>// -------------------------------------------------------------------------\n//  Blend hypsometric tint with shaded relief  \n// -------------------------------------------------------------------------\n</code></pre> <ol> <li>Convert image to rgb \u2192 hillshade  </li> <li>Convert image to rgb \u2192 hypso  </li> <li>Blend two images </li> </ol>"},{"location":"workflows/terrain-workflows/#classified-slope-map","title":"CLASSIFIED SLOPE MAP","text":""},{"location":"workflows/terrain-workflows/#define-study-region_1","title":"Define study region","text":"<pre><code>// -------------------------------------------------------------\n//  DEFINE STUDY REGION\n//\n//  Make two versions of your study region: \n//  1. a feature collection\n//  2. a binary image\n//\n//  Then set up your map:\n//  1. center on study region at zoom 13\n//  2. change base map to hybrid\n// -------------------------------------------------------------\n</code></pre> <ol> <li>Load feature collection from address \u2192 data.gov.town</li> <li>Filter by attribute \u2192 \u2018MIDDLEBURY\u2019</li> <li>Feature collection to binary image </li> </ol>"},{"location":"workflows/terrain-workflows/#load-elevation-data_1","title":"Load elevation data","text":"<pre><code>// -------------------------------------------------------------\n//  LOAD ELEVATION DATA: 3DEP 1m DEM\n// -------------------------------------------------------------\n</code></pre> <ol> <li>Load image collection from address \u2192 \u2018USGS/3DEP/1m\u2019  </li> <li>Filter by bounds \u2192 study_region  </li> <li>Select image band \u2192 \u2018elevation\u2019</li> </ol>"},{"location":"workflows/terrain-workflows/#calculate-percent-of-slope","title":"Calculate percent of slope","text":"<pre><code>// -------------------------------------------------------------\n//  CALCULATE PERCENT OF SLOPE  \n// -------------------------------------------------------------\n</code></pre> <ol> <li>Calculate slope as percent from collection </li> <li>Print min and max of image </li> </ol>"},{"location":"workflows/terrain-workflows/#classify-slope-with-usda-criteria","title":"Classify slope with USDA criteria","text":"<pre><code>// -------------------------------------------------------------------------\n//  CLASSIFY WITH USDA CRITERIA   \n// -------------------------------------------------------------------------\n</code></pre> <ol> <li>Classify slope with USDA criteria </li> </ol>"}]}